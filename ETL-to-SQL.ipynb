{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing essential libraries for pyspark and sql\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-B1QA6MOF.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ETL to SQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x26fdbfafbb0>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "#create spark session\n",
    "spark = SparkSession.builder.config(\"spark.jars\", \"/home/hduser/mysql-connector-java-5.1.47/mysql-connector-java-5.1.47.jar\") \\\n",
    "    .master(\"local\").appName(\"ETL to SQL\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('crypto',)\n"
     ]
    }
   ],
   "source": [
    "#connecting to localhost sql database\n",
    " \n",
    "mydb = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password = \"\",\n",
    "    database ='etl'\n",
    ")\n",
    " \n",
    "# Creating an instance of 'cursor' class\n",
    "# which is used to execute the 'SQL'\n",
    "# statements in 'Python'\n",
    "cursor = mydb.cursor()\n",
    " \n",
    "# Show database tables\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    " \n",
    "for x in cursor:\n",
    "  print(x)\n",
    "\n",
    "#cursor.execute(\"INSERT INTO crypto (Name,Symbol,Date,High,Low,Open,Close,Volume,Marketcap) values('test',0,0,0,0,0,0,0,0)\")\n",
    "#mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for etl processing of dataframe\n",
    "def etl_data(df):\n",
    "    df=df.drop(\"SNo\")\n",
    "    df_date = df.withColumn('Date',to_date(df.Date))\n",
    "    df=df_date\n",
    "    df=df.withColumn(\"High\",round(\"High\",3))\n",
    "    df=df.withColumn(\"Low\",round(\"Low\",3))\n",
    "    df=df.withColumn(\"Open\",round(\"Open\",3))\n",
    "    df=df.withColumn(\"Close\",round(\"Close\",3))\n",
    "    return(df)\n",
    "    #df.select('Name','Symbol','Date','High','Low','Open','Close','Volume','Marketcap').write.format(\"jdbc\").option(\"url\", \"jdbc:mysql://127.0.0.1:3306/dezyre_db&useUnicode=true&characterEncoding=UTF-8&useSSL=false\") \\\n",
    "\t#.option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"students\") \\\n",
    "\t#.option(\"user\", \"root\").option(\"password\", \"root\").save(\n",
    "    #print(\"Successfully cleaned and added data to sql table\")\n",
    "    \n",
    "#define function for upload to sql table    \n",
    "def sql_upload(df):\n",
    "    pd_dataframe=df.toPandas()\n",
    "    for index, row in pd_dataframe.iterrows():\n",
    "        cursor.execute(\"INSERT INTO crypto (Name,Symbol,Date,High,Low,Open,Close,Volume,Marketcap) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",(row['Name'],row['Symbol'],row['Date'],row['High'],row['Low'],row['Open'],row['Close'],row['Volume'],row['Marketcap']))\n",
    "        mydb.commit()\n",
    "    print(\"Successfully uploaded to sql table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----------+-----+-----+-----+-----+--------+-------------+\n",
      "|    Name|Symbol|      Date| High|  Low| Open|Close|  Volume|    Marketcap|\n",
      "+--------+------+----------+-----+-----+-----+-----+--------+-------------+\n",
      "|Dogecoin|  DOGE|2013-12-16|0.001|  0.0|  0.0|  0.0|     0.0|1509085.15965|\n",
      "|Dogecoin|  DOGE|2013-12-17|  0.0|  0.0|  0.0|  0.0|     0.0| 2169687.9813|\n",
      "|Dogecoin|  DOGE|2013-12-18|  0.0|  0.0|  0.0|  0.0|     0.0|3188943.20963|\n",
      "|Dogecoin|  DOGE|2013-12-19|0.002|  0.0|  0.0|0.001|     0.0|11150339.2183|\n",
      "|Dogecoin|  DOGE|2013-12-20|0.001|0.001|0.001|0.001|     0.0|7284337.11836|\n",
      "|Dogecoin|  DOGE|2013-12-21|0.001|  0.0|0.001|  0.0|     0.0|4360316.34343|\n",
      "|Dogecoin|  DOGE|2013-12-22|  0.0|  0.0|  0.0|  0.0|     0.0|3706592.18772|\n",
      "|Dogecoin|  DOGE|2013-12-23|  0.0|  0.0|  0.0|  0.0|     0.0|5644793.35139|\n",
      "|Dogecoin|  DOGE|2013-12-24|0.001|  0.0|  0.0|0.001|     0.0|9075937.82287|\n",
      "|Dogecoin|  DOGE|2013-12-25|0.001|0.001|0.001|0.001|     0.0|8194483.24403|\n",
      "|Dogecoin|  DOGE|2013-12-26|0.001|0.001|0.001|0.001|     0.0| 8836621.0156|\n",
      "|Dogecoin|  DOGE|2013-12-27|0.001|  0.0|0.001|0.001|477422.0|8016603.64892|\n",
      "|Dogecoin|  DOGE|2013-12-28|0.001|  0.0|0.001|  0.0|341581.0|7374148.77651|\n",
      "|Dogecoin|  DOGE|2013-12-29|  0.0|  0.0|  0.0|  0.0|360974.0|7634717.16966|\n",
      "|Dogecoin|  DOGE|2013-12-30|  0.0|  0.0|  0.0|  0.0|276660.0|7270541.89933|\n",
      "|Dogecoin|  DOGE|2013-12-31|  0.0|  0.0|  0.0|  0.0|273400.0|7689658.67317|\n",
      "|Dogecoin|  DOGE|2014-01-01|  0.0|  0.0|  0.0|  0.0|307917.0|8335005.00046|\n",
      "|Dogecoin|  DOGE|2014-01-02|  0.0|  0.0|  0.0|  0.0|318037.0|6935467.09731|\n",
      "|Dogecoin|  DOGE|2014-01-03|  0.0|  0.0|  0.0|  0.0|303106.0| 6162989.7455|\n",
      "|Dogecoin|  DOGE|2014-01-04|  0.0|  0.0|  0.0|  0.0|313907.0|6323971.51966|\n",
      "+--------+------+----------+-----+-----+-----+-----+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check if etl worked\n",
    "doge_df = spark.read.csv('csv\\\\coin_Dogecoin.csv', header=True, sep=\",\").cache()\n",
    "etl_doge=etl_data(doge_df)\n",
    "etl_doge.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded to sql table\n"
     ]
    }
   ],
   "source": [
    "sql_upload(etl_doge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df = spark.read.csv('csv\\\\coin_Bitcoin.csv', header=True, sep=\",\").cache()\n",
    "etl_btc=etl_data(btc_df)\n",
    "sql_upload(etl_btc)\n",
    "\n",
    "aave_df = spark.read.csv('csv\\\\coin_Aave.csv', header=True, sep=\",\").cache()\n",
    "etl_aave=etl_data(aave_df)\n",
    "sql_upload(etl_aave)\n",
    "\n",
    "binance_df = spark.read.csv('csv\\\\coin_BinanceCoin.csv', header=True, sep=\",\").cache()\n",
    "etl_binance=etl_data(binance_df)\n",
    "sql_upload(etl_binance)\n",
    "\n",
    "cardano_df = spark.read.csv('csv\\\\coin_Cardano.csv', header=True, sep=\",\").cache()\n",
    "etl_cardano=etl_data(cardano_df)\n",
    "sql_upload(etl_cardano)\n",
    "\n",
    "usdt_df = spark.read.csv('csv\\\\coin_Tether.csv', header=True, sep=\",\").cache()\n",
    "etl_usdt=etl_data(usdt_df)\n",
    "sql_upload(etl_usdt)\n",
    "\n",
    "ethereum_df = spark.read.csv('csv\\\\coin_Ethereum.csv', header=True, sep=\",\").cache()\n",
    "etl_ethereum=etl_data(ethereum_df)\n",
    "sql_upload(etl_ethereum)\n",
    "\n",
    "solana_df = spark.read.csv('csv\\\\coin_Solana.csv', header=True, sep=\",\").cache()\n",
    "etl_solana=etl_data(solana_df)\n",
    "sql_upload(etl_solana)\n",
    "\n",
    "lite_df = spark.read.csv('csv\\\\coin_Litecoin.csv', header=True, sep=\",\").cache()\n",
    "etl_lite=etl_data(lite_df)\n",
    "sql_upload(etl_lite)\n",
    "\n",
    "stellar_df = spark.read.csv('csv\\\\coin_Stellar.csv', header=True, sep=\",\").cache()\n",
    "etl_stellar=etl_data(stellar_df)\n",
    "sql_upload(etl_stellar)\n",
    "\n",
    "usd_df = spark.read.csv('csv\\\\coin_USDCoin.csv', header=True, sep=\",\").cache()\n",
    "etl_usd=etl_data(usd_df)\n",
    "sql_upload(etl_usd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
