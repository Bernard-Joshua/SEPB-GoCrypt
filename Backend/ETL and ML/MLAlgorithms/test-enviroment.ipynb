{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt\nimport tensorflow as tf\nfrom sklearn.preprocessing import RobustScaler, MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom tensorflow.keras import Sequential # Deep learning library, used for neural networks\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout # Deep learning classes for recurrent and regular densely-connected layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint # EarlyStopping during model training\nfrom tensorflow.keras.optimizers import Adam\nimport math\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-01T23:25:17.796156Z","iopub.execute_input":"2022-12-01T23:25:17.797026Z","iopub.status.idle":"2022-12-01T23:25:24.229536Z","shell.execute_reply.started":"2022-12-01T23:25:17.796931Z","shell.execute_reply":"2022-12-01T23:25:24.228590Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/testvalidation/Test.csv\n/kaggle/input/etherum-2022-minbymin/ETHUSDT_Binance_futures_2022_minute.csv\n/kaggle/input/real-validation/Day 2.csv\n/kaggle/input/real-validation/Day 3.csv\n/kaggle/input/real-validation/Day 1.csv\n/kaggle/input/real-validation/Day 5.csv\n/kaggle/input/real-validation/Day 4.csv\n/kaggle/input/real-validation/Day 7.csv\n/kaggle/input/real-validation/Day 6.csv\n/kaggle/input/etherum-model/Ethereum_Model/saved_model.pb\n/kaggle/input/etherum-model/Ethereum_Model/keras_metadata.pb\n/kaggle/input/etherum-model/Ethereum_Model/variables/variables.index\n/kaggle/input/etherum-model/Ethereum_Model/variables/variables.data-00000-of-00001\n/kaggle/input/etherum/ETH-USD.csv\n/kaggle/input/eth-updated/Ethereum_Updated_Model/saved_model.pb\n/kaggle/input/eth-updated/Ethereum_Updated_Model/keras_metadata.pb\n/kaggle/input/eth-updated/Ethereum_Updated_Model/variables/variables.index\n/kaggle/input/eth-updated/Ethereum_Updated_Model/variables/variables.data-00000-of-00001\n/kaggle/input/valid-or-not/ETH-USD.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# This file is used as a test enviroment to build the perfect LSTM model with high accuracy.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/etherum-2022-minbymin/ETHUSDT_Binance_futures_2022_minute.csv')\n# Removing all unessesary columns ( See Research )\ndf = df = df.drop([\"Volume ETH\", \"unix\",\"Volume USDT\", \"symbol\",\"open\",\"tradecount\"], axis=1)\ndf['date'] = pd.to_datetime(df['date'])\ndf = df.sort_values(by='date')\ndf.index = df.pop(\"date\")\ndf","metadata":{"execution":{"iopub.status.busy":"2022-12-01T23:27:29.093344Z","iopub.execute_input":"2022-12-01T23:27:29.093822Z","iopub.status.idle":"2022-12-01T23:28:01.398494Z","shell.execute_reply.started":"2022-12-01T23:27:29.093782Z","shell.execute_reply":"2022-12-01T23:28:01.397562Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                        high      low    close\ndate                                          \n2022-01-01 00:01:00  3692.29  3681.11  3690.61\n2022-01-01 00:02:00  3692.94  3685.66  3692.00\n2022-01-01 00:03:00  3693.93  3688.21  3689.25\n2022-01-01 00:04:00  3689.69  3686.55  3688.53\n2022-01-01 00:05:00  3698.26  3685.00  3697.77\n...                      ...      ...      ...\n2022-09-07 00:12:00  1562.67  1561.08  1561.09\n2022-09-07 00:13:00  1561.98  1560.01  1560.99\n2022-09-07 00:14:00  1562.00  1560.50  1560.88\n2022-09-07 00:15:00  1562.76  1560.58  1561.51\n2022-09-07 00:16:00  1561.50  1555.82  1556.24\n\n[358576 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2022-01-01 00:01:00</th>\n      <td>3692.29</td>\n      <td>3681.11</td>\n      <td>3690.61</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:02:00</th>\n      <td>3692.94</td>\n      <td>3685.66</td>\n      <td>3692.00</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:03:00</th>\n      <td>3693.93</td>\n      <td>3688.21</td>\n      <td>3689.25</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:04:00</th>\n      <td>3689.69</td>\n      <td>3686.55</td>\n      <td>3688.53</td>\n    </tr>\n    <tr>\n      <th>2022-01-01 00:05:00</th>\n      <td>3698.26</td>\n      <td>3685.00</td>\n      <td>3697.77</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2022-09-07 00:12:00</th>\n      <td>1562.67</td>\n      <td>1561.08</td>\n      <td>1561.09</td>\n    </tr>\n    <tr>\n      <th>2022-09-07 00:13:00</th>\n      <td>1561.98</td>\n      <td>1560.01</td>\n      <td>1560.99</td>\n    </tr>\n    <tr>\n      <th>2022-09-07 00:14:00</th>\n      <td>1562.00</td>\n      <td>1560.50</td>\n      <td>1560.88</td>\n    </tr>\n    <tr>\n      <th>2022-09-07 00:15:00</th>\n      <td>1562.76</td>\n      <td>1560.58</td>\n      <td>1561.51</td>\n    </tr>\n    <tr>\n      <th>2022-09-07 00:16:00</th>\n      <td>1561.50</td>\n      <td>1555.82</td>\n      <td>1556.24</td>\n    </tr>\n  </tbody>\n</table>\n<p>358576 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Scaler for N-Dimensional Array\ndf_features = df\ndf_np = df_features.to_numpy()\nscaler = MinMaxScaler()\ndf_scaled = scaler.fit_transform(df_np, (-1,1))\ndf_scaled[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-01T23:28:06.937019Z","iopub.execute_input":"2022-12-01T23:28:06.937386Z","iopub.status.idle":"2022-12-01T23:28:06.956287Z","shell.execute_reply.started":"2022-12-01T23:28:06.937356Z","shell.execute_reply":"2022-12-01T23:28:06.955287Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([0.93307773, 0.93242654, 0.93452141])"},"metadata":{}}]},{"cell_type":"code","source":"# Scaler for 1D array\ndf_close = pd.DataFrame(df['close'])\ndf_close_np = df_close.to_numpy()\nto_inverse_scale = MinMaxScaler()\ndf_close_scale = to_inverse_scale.fit_transform(df_close_np)\ndf_close_scale","metadata":{"execution":{"iopub.status.busy":"2022-12-01T23:28:10.129189Z","iopub.execute_input":"2022-12-01T23:28:10.129663Z","iopub.status.idle":"2022-12-01T23:28:10.146298Z","shell.execute_reply.started":"2022-12-01T23:28:10.129623Z","shell.execute_reply":"2022-12-01T23:28:10.145062Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([[0.93452141],\n       [0.93498417],\n       [0.93406864],\n       ...,\n       [0.22549297],\n       [0.22570271],\n       [0.22394822]])"},"metadata":{}}]},{"cell_type":"code","source":"x = [] # The features needed for prediction.\ny = [] # The expected result.\n\nfor i in range(len(df_scaled)-7):\n    x.append(df_scaled[i:i+7])\n\nfor i in range(len(df_close_scale)-1):\n        y.append(df_close_scale[i][0])\n\n\n# Converting to Numpy array for easier reading by the ML-Algorithm\nX = np.array(x)\nY = np.array(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_no = math.floor(len(X) * 0.7) # 70% for training, 30% For Testing\ntotal_no = len(X) \nX_Train, Y_Train = X[:train_no][:train_no], Y[:train_no]\nX_Test, Y_Test = X[train_no: total_no - 1], Y[train_no: total_no - 1]\nprint(X_Train.shape, Y_Train.shape)\nprint(X_Test.shape, Y_Test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model#1","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model#2","metadata":{}},{"cell_type":"code","source":"model2 = Sequential()\n# 8 layers, Final Output is in an array of 1 predictions\nmodel2.add(LSTM(200, return_sequences=True, input_shape=(7,3)))\nmodel2.add(LSTM(150, return_sequences=True))\nmodel2.add(LSTM(100, return_sequences=True))\nmodel2.add(LSTM(50, return_sequences=False))\nmodel2.add(Dense(15))\nmodel2.add(Dense(10))\nmodel2.add(Dense(5))\nmodel2.add(Dense(1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model3 = Sequential()\n# Final Output is in an array of 1 predictions\nmodel3.add(LSTM(300, return_sequences=True, input_shape=(7,3)))\nmodel3.add(LSTM(250, return_sequences=True))\nmodel3.add(LSTM(200, return_sequences=True))\nmodel3.add(LSTM(150, return_sequences=True))\nmodel3.add(LSTM(100, return_sequences=True))\nmodel3.add(LSTM(50, return_sequences=False))\nmodel3.add(Dense(20))\nmodel3.add(Dense(15))\nmodel3.add(Dense(10))\nmodel3.add(Dense(5))\nmodel3.add(Dense(1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 4","metadata":{}},{"cell_type":"code","source":"model4 = Sequential()\n\nmodel4.add(LSTM(300, return_sequences=True, input_shape=(7,3)))\nmodel4.add(LSTM(250, return_sequences=True))\nmodel4.add(LSTM(200, return_sequences=True))\nmodel4.add(LSTM(150, return_sequences=True))\nmodel4.add(LSTM(100, return_sequences=True))\nmodel4.add(LSTM(50, return_sequences=False))\nmodel4.add(Dense(25))\nmodel4.add(Dense(20))\nmodel4.add(Dense(15))\nmodel4.add(Dense(10))\nmodel4.add(Dense(5))\nmodel4.add(Dense(1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 5","metadata":{}},{"cell_type":"code","source":"model5 = Sequential()\nmodel5.add(LSTM(400, return_sequences=True, input_shape=(7,3)))\nmodel5.add(LSTM(350, return_sequences=True))\nmodel5.add(LSTM(300, return_sequences=True))\nmodel5.add(LSTM(250, return_sequences=True))\nmodel5.add(LSTM(200, return_sequences=True))\nmodel5.add(LSTM(150, return_sequences=True))\nmodel5.add(LSTM(100, return_sequences=True))\nmodel5.add(LSTM(50, return_sequences=False))\nmodel5.add(Dense(30))\nmodel5.add(Dense(25))\nmodel5.add(Dense(20))\nmodel5.add(Dense(15))\nmodel5.add(Dense(10))\nmodel5.add(Dense(5))\nmodel5.add(Dense(1))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T23:44:45.144442Z","iopub.execute_input":"2022-12-01T23:44:45.145425Z","iopub.status.idle":"2022-12-01T23:44:46.846594Z","shell.execute_reply.started":"2022-12-01T23:44:45.145387Z","shell.execute_reply":"2022-12-01T23:44:46.845628Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Gets the current models structure.","metadata":{}},{"cell_type":"code","source":"model5.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T23:44:49.564729Z","iopub.execute_input":"2022-12-01T23:44:49.565127Z","iopub.status.idle":"2022-12-01T23:44:49.574552Z","shell.execute_reply.started":"2022-12-01T23:44:49.565088Z","shell.execute_reply":"2022-12-01T23:44:49.573272Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 7, 400)            646400    \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 7, 350)            1051400   \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 7, 300)            781200    \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 7, 250)            551000    \n_________________________________________________________________\nlstm_4 (LSTM)                (None, 7, 200)            360800    \n_________________________________________________________________\nlstm_5 (LSTM)                (None, 7, 150)            210600    \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 7, 100)            100400    \n_________________________________________________________________\nlstm_7 (LSTM)                (None, 50)                30200     \n_________________________________________________________________\ndense (Dense)                (None, 30)                1530      \n_________________________________________________________________\ndense_1 (Dense)              (None, 25)                775       \n_________________________________________________________________\ndense_2 (Dense)              (None, 20)                520       \n_________________________________________________________________\ndense_3 (Dense)              (None, 15)                315       \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                160       \n_________________________________________________________________\ndense_5 (Dense)              (None, 5)                 55        \n_________________________________________________________________\ndense_6 (Dense)              (None, 1)                 6         \n=================================================================\nTotal params: 3,735,361\nTrainable params: 3,735,361\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Compiliation and Fitting Model","metadata":{}},{"cell_type":"code","source":"model2.compile(optimizer=\"Adam\", loss='mean_squared_error') # Compling the Model\ncallback = [EarlyStopping(monitor='loss', patience=10, verbose=1, mode='min')] # Stops from overfitting\nmodeled = model2.fit(X_Train, Y_Train, batch_size=500, epochs=100, callbacks=callback) # Training the","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions","metadata":{}},{"cell_type":"code","source":"#x = X_Test.reshape(-1,1)\npredictions = model2.predict(X_Test)\npredictions = to_inverse_scale.inverse_transform(predictions) # Reverse the standardization.\n#predictions\n# Putting the predictions in an array to convert into dataframe column later.\nvalid = []\nfor i in range(len(predictions)):\n    valid.append(predictions[i][0]) # Using the final prediction in the array.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = pd.DataFrame(df[train_no: total_no - 1])\nnew_df = new_df.drop([\"high\",\"low\"], axis=1)\nnew_df['Prediction'] = valid\n\n\nnew_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\n#print(mean(modeled.history['mse']))\n#print(mean(modeled.history['mape']))\n#print(mean(modeled.history['rmse']))\n\n\nfrom sklearn.metrics import mean_absolute_percentage_error\nfrom sklearn.metrics import mean_absolute_error\nmape = mean_absolute_percentage_error(new_df['close'].values, new_df['Prediction'].values)\nmae = mean_absolute_error(new_df['close'].values, new_df['Prediction'].values)\nprint(mape)\nprint(mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.save('myTestModel')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing Independant Enviroment\nThe model ceases to exist above and is load below using TensorFlow functions.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/etherum/ETH-USD.csv')\nnew_df = pd.read_csv('../input/etherum/ETH-USD.csv')\n# Removing all unessesary columns ( See Research )\ndf = df.drop([\"Volume\", \"Adj Close\",\"Open\"], axis=1)\nnew_df = new_df.drop([\"Volume\", \"High\", \"Low\",\"Adj Close\",\"Open\"], axis=1)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values(by='Date')\ndf.index = df.pop(\"Date\")\n\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_np = df.to_numpy()\nscaler = MinMaxScaler()\ndf_scaled = scaler.fit_transform(df_np, (-1,1))\ndf_scaled.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = []\n\nfor i in range(len(df_scaled)-7):\n    test.append(df_scaled[i:i+7])\n    \ntest = np.array(test)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model = tf.keras.models.load_model('/kaggle/input/etherum-model/Ethereum_Model')\nnew_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = new_model.predict(test)\nprediction = to_inverse_scale.inverse_transform(prediction) \n\npredictions\nvalid = []\nfor i in range(len(prediction)):\n    valid.append(prediction[i][0]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#new_df = pd.read_csv('/kaggle/input/btcdata/BTC-USD.csv')\nnew_df = df[:359]\nnew_df = new_df.drop([ \"High\", \"Low\"], axis=1)\nnew_df['Prediction'] = valid\n\n\nnew_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_percentage_error\nfrom sklearn.metrics import mean_absolute_error\nmape = mean_absolute_percentage_error(new_df['Close'].values, new_df['Prediction'].values)\nmae = mean_absolute_error(new_df['Close'].values, new_df['Prediction'].values)\nprint(mape)\nprint(mae)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadDataPrediction(df_test):\n    df = df_test\n    real_df = df.drop([\"Volume\",\"Adj Close\",\"Open\"], axis=1)\n    real_df['Date'] = pd.to_datetime(real_df['Date'])\n    real_df = real_df.sort_values(by='Date')\n    real_df.index = real_df.pop(\"Date\")\n    \n    scaler = MinMaxScaler()\n    df_scaled = scaler.fit_transform(real_df, (-1,1))\n    n_df = df_scaled.reshape(1,7,3)\n    print(n_df.shape)\n    test =  new_model.predict(n_df)\n    test = to_inverse_scale.inverse_transform(test)\n    \n    return test\n\ndef customUnitTest(actual, pred):\n    mape = mean_absolute_percentage_error(actual, pred)\n    \n    if( mape <= 0.2):\n        print(\"Passed Test: 7\")\n        print(mape)\n    else:\n        print(\"Failed Test: 7\")\n        print(mape)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T23:28:18.297122Z","iopub.execute_input":"2022-12-01T23:28:18.297478Z","iopub.status.idle":"2022-12-01T23:28:18.306005Z","shell.execute_reply.started":"2022-12-01T23:28:18.297449Z","shell.execute_reply":"2022-12-01T23:28:18.304867Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"day1_df = pd.read_csv('/kaggle/input/real-validation/Day 1.csv')\nday2_df = pd.read_csv('/kaggle/input/real-validation/Day 2.csv')\nday3_df = pd.read_csv('/kaggle/input/real-validation/Day 3.csv')\nday4_df = pd.read_csv('/kaggle/input/real-validation/Day 4.csv')\nday5_df = pd.read_csv('/kaggle/input/real-validation/Day 5.csv')\nday6_df = pd.read_csv('/kaggle/input/real-validation/Day 6.csv')\nday7_df = pd.read_csv('/kaggle/input/real-validation/Day 7.csv')\n\n\ntest = pd.read_csv('/kaggle/input/valid-or-not/ETH-USD.csv')\n\n\n\nday_1 = loadDataPrediction(test)\nday_2 = loadDataPrediction(day2_df)\nday_3 = loadDataPrediction(day3_df)\nday_4 = loadDataPrediction(day4_df)\nday_5 = loadDataPrediction(day5_df)\nday_6 = loadDataPrediction(day6_df)\nday_7 = loadDataPrediction(day7_df)\n\npred = [day_1[0][0], day_2[0][0], day_3[0][0], day_4[0][0], day_5[0][0], day_6[0][0], day_7[0][0]]\n#print(pred)\n#print(day_1)\n#print(test['Close'])\nday_1\n#customUnitTest(test['Close'].values, pred)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T23:28:21.621073Z","iopub.execute_input":"2022-12-01T23:28:21.621440Z","iopub.status.idle":"2022-12-01T23:28:21.945184Z","shell.execute_reply.started":"2022-12-01T23:28:21.621409Z","shell.execute_reply":"2022-12-01T23:28:21.944024Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(1, 7, 3)\n(1, 7, 3)\n(1, 7, 3)\n(1, 7, 3)\n(1, 7, 3)\n(1, 7, 3)\n(1, 7, 3)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([[2212.7468]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}